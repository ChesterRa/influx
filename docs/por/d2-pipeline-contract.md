# D2 Collection Pipeline Contract

**Version**: 1.3.0 (M2 Activity Metrics Integration)
**Owner**: PeerA (architecture) + PeerB (implementation)
**Purpose**: Define the **mandatory single-path ingestion process** via `influx-harvest` CLI with JSONL I/O format, rate-limit guardrails, M2 activity metrics integration, and filter specifications for all data collection

## Executive Summary

**MANDATORY SINGLE-PATH**: All data ingestion **MUST** flow through `influx-harvest` CLI tool. This path is **proven operational** with 610 authors processed at 153% of target and 100% quality compliance. **NO BYPASSES ALLOWED** - any alternative ingestion method is considered a critical security vulnerability and quality risk.

**M2 INTEGRATION COMPLETE**: Successfully integrated real Twitter API v2 activity metrics for 385 authors, implemented M2 scoring model (activity 30% + quality 50% + relevance 20%), and updated schema to support activity_metrics object. Production-ready pipeline with $60K/year cost savings maintained.

---

## Changelog

### v1.3.0 (2025-11-19) - M2 Activity Metrics Integration
- **INTEGRATED**: M2 activity metrics from Twitter API v2 public_metrics into core schema
- **ENHANCED**: Scoring model to M2 formula (activity 30% + quality 50% + relevance 20%)
- **VALIDATED**: 610 authors with real activity metrics, score range 8.2-43.2 (avg 24.9)
- **UPDATED**: Schema v1.0.0 with activity_metrics object supporting both like_count/total_like_count fields
- **OPERATIONAL**: $60K/year cost savings maintained with production-ready M2 pipeline

### v1.2.0 (2025-11-14) - Single-Path Operational Excellence
- **MANDATED**: Single-path ingestion via `influx-harvest` CLI ONLY (P0 crisis proven bypass prevention)
- **PERMANENT**: Removed all automation probe sections (GitHub automation paths decommissioned)
- **VALIDATED**: Process proven with 408 authors (102% of 400 target), 100% quality compliance
- **EVIDENCE**: Crisis recovery from 292 contaminated records to operational excellence through strict pipeline adherence
- **FOREFORCE**: Foreman directive #000166: "Your focus should now shift to M2 planning. This includes... updating documentation to permanently reflect the single-path pipeline"

### v1.1.0 (2025-11-13) - M1 Manual CSV+Lists
- **ADDED**: Filter Implementation Specification (CLI flags, YAML keys, smoke test) - NORMATIVE for M1 Week 1 (commit 9779756)
- **SCOPE PIVOT**: GitHub automation endpoints (`github-seeds`, `following`) marked DEFERRED (RUBE MCP `read:org` scope unavailable per T000003)
- **STATUS**: M1 primary method = manual CSV curation + curated X Lists + batch TWITTER_USER_LOOKUP validation
- **PRESERVED**: Automation probe sections retained for M2 reference (clearly marked DEFERRED)

### v1.0.0 (2025-11-13) - M0 Baseline
- Initial contract with automation probe acceptance criteria
- Proxy scoring formula v0, validation contract, evidence requirements

---

## Single-Path Ingestion Mandate

### üö® CRITICAL SECURITY POLICY

**MANDATORY**: ALL data ingestion **MUST** flow through `influx-harvest` CLI tool. **NO EXCEPTIONS**.

**RISK CLASSIFICATION**: Any bypass of `influx-harvest` is classified as **CRITICAL SECURITY VULNERABILITY** and **QUALITY RISK**.

**VALIDATION**: This mandate is **proven operational** with:
- ‚úÖ **408 authors processed** (102% of 400 target)
- ‚úÖ **100% quality compliance** (0 contaminated records)
- ‚úÖ **P0 crisis recovery** (292 ‚Üí 408 authors through strict adherence)

### Operational Workflow (M1 and beyond)

**The ONLY approved ingestion method**:
```bash
# STEP 1: Manual CSV curation ‚Üí X Lists validation
influx-harvest x-lists \
  --list-urls lists/seeds/[batch-file].csv \
  --out harvest.raw.jsonl

# STEP 2: Proxy scoring (v0)
influx-score update \
  --authors harvest.raw.jsonl \
  --out scored.jsonl

# STEP 3: Validation and export
influx-validate --input scored.jsonl --schema schema/bigv.schema.json
influx-export --input scored.jsonl --out data/latest/latest.jsonl.gz
```

### Prohibited Actions
To maintain data integrity and prevent a recurrence of the P0 quality crisis, the following actions are strictly forbidden:
- **DO NOT** use `tools/influx-clean.py` or any other script to modify the dataset. All cleaning, filtering, and transformation is handled by `influx-harvest`.
- **DO NOT** manually edit the `latest.jsonl` or any other data artifact.
- **DO NOT** introduce any new data ingestion scripts or processes without a formal review and update to this contract.

### Historical Context (Lessons Learned)

**DECOMMISSIONED PATHS** - Never to be revived:
- ‚ùå **GitHub automation**: Required `read:org` scope - permanently unavailable
- ‚ùå **Following-graph expansion**: Low value without proper seed validation
- ‚ùå **Direct database insertion**: Bypassed quality gates (caused P0 crisis)
- ‚ùå **Manual JSON creation**: Missing validation, provenance tracking

**CRISIS ROOT CAUSE**: P0 quality crisis (292 contaminated records) was caused by bypassing `influx-harvest` quality gates.

**RECOVERY**: Achieved through strict 100% compliance with single-path ingestion.

---

## Tool Interfaces

### influx-harvest (Author Discovery)

**M1 Active Method** (manual CSV + X Lists):
```bash
# Manual CSV curation ‚Üí TWITTER_USER_LOOKUP batch validation ‚Üí filters
# See "Filter Implementation Specification" section below for CLI flags

influx-harvest x-lists \
  --list-urls lists/seeds/m04-business-batch.csv \
  --out harvest.raw.jsonl
```

**‚è∏Ô∏è DEFERRED to M2** (GitHub automation - `read:org` scope unavailable per T000003):
```bash
# GitHub org seeds (40-50% of M0 target) - BLOCKED
influx-harvest github-seeds \
  --orgs openai,anthropic,pytorch,huggingface \
  --out github_seeds.jsonl

# Following-graph expansion (40-50% of M0 target) - DEFERRED
influx-harvest following \
  --seeds github_seeds.jsonl \
  --pages 2 \
  --out following_expanded.jsonl
```

**Outputs**: JSONL with minimal author records:
```jsonl
{"id": "12345", "handle": "username", "name": "Display Name", "verified": "blue", "followers_count": 50000, "lang_primary": "en", "topic_tags": ["ai"], "sources": [{"method": "github_seed", "fetched_at": "2025-11-13T12:00:00Z", "evidence": "github.com/openai"}]}
```

### influx-score (Scoring & Ranking)

```bash
# Score new authors (30d metrics window)
influx-score update \
  --authors combined.jsonl \
  --window-days 30 \
  --out scored.jsonl
```

**Outputs**: JSONL with added `score`, `rank_global`, `meta` fields (must validate against schema/bigv.schema.json)

### influx-export (Publication)

```bash
# Export to latest release
influx-export latest \
  --input scored.jsonl \
  --out data/latest/
```

**Outputs**:
- `data/latest/latest.jsonl.gz` (sorted by score desc ‚Üí followers desc ‚Üí handle lex)
- `data/latest/manifest.json` (schema_version, timestamp, count, sha256)

---

## Data Flow (M1 Manual CSV+Lists)

```
Manual CSV curation (GitHub org pages, X Lists, domain seeds)
                                    ‚Üì
                    lists/seeds/*.csv (~250-300 handles/week)
                                    ‚Üì
                    TWITTER_USER_LOOKUP (batch 100/call)
                                    ‚Üì
                    influx-harvest x-lists (apply filters)
                                    ‚Üì
                    harvest.filtered.jsonl (~200-250 authors after filters)
                                    ‚Üì
                    influx-score update (proxy v0 scoring)
                                    ‚Üì
                    scored.jsonl (validated via influx-validate)
                                    ‚Üì
                    influx-export latest
                                    ‚Üì
                    data/latest/latest.jsonl.gz + manifest.json
                                    ‚Üì
                    snapshot.yml workflow (daily cron)
                                    ‚Üì
                    data/snapshots/YYYY-MM-DD/
```

### ‚è∏Ô∏è DEFERRED: M0 Automation Data Flow (Reference Only)

```
[BLOCKED] GitHub Orgs ‚Üí github-seeds ‚Üí following expansion ‚Üí merge+dedupe ‚Üí all_authors.jsonl
          [See v1.0.0 for original automation flow diagram - deferred pending RUBE MCP scope upgrade]
```

---

## Gating Filters (Applied at Collection Time)

### Entry Filters (influx-harvest)
1. **Follower threshold**: `(verified == true AND followers_count >= 30000) OR followers_count >= 50000`
2. **Language preference**: `lang_primary IN ('en', 'ja')` (best-effort; not hard gate for M0)
3. **Activity minimum**: Skip if author has 0 recent tweets (indicates suspended/inactive)

### Brand/Official Heuristics (lists/rules/brand_heuristics.yml)
- Name/bio/username contains: `Official`, `News`, `Press`, `PR`, `Team`, `Support`, `Corp`, `Media`, `Store`, `Shop`
- Domain patterns (when available): news sites, e-commerce, corporate homepages
- Action: Set `is_org=true` or `is_official=true`; exclude from M0 pool

### Risk Terms (lists/rules/risk_terms.yml)
- Keywords: `nsfw`, `political`, `controversy`, `spam`, `hate_speech`
- Action: Set `risk_flags=[...]`; exclude from M0 pool by default

### Boundary Terms (FP-Prone Keywords) - M1 Tuning Guide

**Context**: Certain brand/risk keywords require context-sensitive matching to avoid false positives. NOTEs added to `brand_heuristics.yml` (2025-11-13) based on `.cccc/work/review/brand_fp.sample.csv` analysis (20 test cases).

**FP-Prone Terms & Mitigation**:
- **"inc"** (corporate_indicators): May match personal nicknames (e.g., "John Doe Inc"). Mitigation: Check verified status (blue) + personal bio context ("personal views", "tweets my own").
- **"shop"** (brand_commerce): May match job descriptions (e.g., "engineer at Shopify"). Mitigation: Recommend word-boundary match in implementation (not substring); exempt if combined with "at [CompanyName]" pattern.
- **"team"** (official_indicators): May match gaming/esports teams (e.g., "Team Liquid player"). Mitigation: Exempt if bio contains gaming indicators (esports, streaming, competitive, tournament); check domain context.

**Implementation Notes**:
- Current YAMLs use substring matching for speed; boundary-aware matching may be added in M2.
- Manual QA samples (N=30 per batch) catch remaining edge cases; add to `brand_heuristics.yml:exceptions` list as discovered.
- Trade-off: Loose matching (current) = faster, ‚â§5% FP rate (acceptable for manual QC); strict matching = slower, higher implementation complexity.

**Evidence**: FP analysis documented in `.cccc/work/review/brand_fp.validation.txt` (141 lines, generated 2025-11-13).

### ‚úÖ Filter Implementation Specification (M1 Week 1) - NORMATIVE

**Status**: ACTIVE for M1 - PeerB implementation complete (commit 6fd9487)

**CLI Flags** (`influx-harvest`):
- `--min-followers N`: Entry threshold (default: 50000)
- `--verified-min-followers N`: Lower threshold for verified accounts (default: 30000)
- `--brand-rules PATH`: Brand heuristics YAML (default: `lists/rules/brand_heuristics.yml`)
- `--risk-rules PATH`: Risk terms YAML (default: `lists/rules/risk_terms.yml`)
- `--allow-brands`: Disable brand exclusion (default: false)
- `--allow-risk FLAGS`: Comma-separated risk flags to allow (default: none)

**YAML Keys Used**: `name_keywords.{official_indicators,corporate_indicators,brand_commerce}`, `bio_keywords.{organizational,service_language}`, `domain_patterns`, `verification_rules.flag_org_verification`, `confidence_weights.*` (brand); `nsfw.{bio_keywords,flag_name,auto_exclude}`, `political.*`, `controversy.*`, `spam.*` (risk)

**Smoke Test**:
```bash
python3 tools/influx-harvest x-lists --list-urls lists/seeds/m03-additional-batch.csv --out .cccc/work/m01/harvest.raw.jsonl && python3 tools/influx-validate -s schema/bigv.schema.json .cccc/work/m01/harvest.raw.jsonl
```

**Acceptance**: (1) Filters enforced at harvest; zero brand/official accounts in output (spot-check N=30 random sample). (2) Risk flags excluded by default; output passes schema validation with ‚â•40 records.

---

## Rate Limit Guardrails (POR R1)

### TWITTER_FOLLOWING Pagination
- **Pages per seed**: ‚â§ 2 pages (~200 follows per seed)
- **Batch size**: Max 50 seeds per run
- **Total API calls per run**: ‚â§ 150 calls
  - GitHub org members: ~20-30 calls (GITHUB_SEARCH_USERS + GITHUB_GET_A_USER per member)
  - Twitter user lookup: ~50-100 calls (TWITTER_USER_LOOKUP_BY_USERNAMES, batch of 100)
  - Following expansion: ~50-100 calls (TWITTER_FOLLOWING_BY_USER_ID, 2 pages √ó 50 seeds)

### Error Handling
- **429 TooManyRequests**: Exponential backoff (2s ‚Üí 4s ‚Üí 8s ‚Üí 16s ‚Üí stop)
- **Per-run caps**: Stop after 150 API calls OR 429 with retry-after > 60s
- **Batch by topic/lang**: Split large runs into smaller batches (max 50 seeds each)

---

## Out-of-Scope (Per Pivot Decision POR#L39)

### Prohibited Endpoints (Paid/Elevated API)
- ‚ùå `TWITTER_RECENT_SEARCH` (requires paid tier per Aux validation)
- ‚ùå `TWITTER_RECENT_SEARCH_COUNTS` (requires paid tier)
- ‚ùå `TWITTER_SEARCH_ADAPTIVE` (hypothetical; not available in free tier)

### Deferred to M1
- Keyword-based discovery (radar + search) - only if free-tier access confirmed
- Incremental 6-12h refresh (M0 = one-shot collection)
- Following-of-following (2-hop expansion; defer until 1-hop validated)

---

## Validation Contract

All JSONL outputs MUST pass:
```bash
python3 tools/influx-validate -s schema/bigv.schema.json <input.jsonl>
```

Exit code 0 = valid; non-zero = schema violation (CI blocks merge).

### Intermediate Artifact Compliance Strategy

**Problem**: Schema requires `meta` object with `score`, `last_refresh_at`, `sources`, `provenance_hash` (all required per schema/bigv.schema.json:L220-225), but intermediate outputs from `influx-harvest` lack scores (scoring occurs in `influx-score`).

**Solution (Option A - IMPLEMENTED M0.0)**: `influx-harvest` writes **minimal compliant meta**; `influx-score` computes proxy scores:
- `meta.score`: **Proxy formula v0** (M0.0+): `20*log10(max(followers_count/1000, 1)) + verified_boost`, clipped [0,100]
  - Verified boost: {blue: 10, legacy: 5, org: 0, none: 0}
  - Deterministic, no API calls, sortable prioritization
  - M1 will replace with full formula (activity 30% + quality 50% + relevance 20% with 30d metrics)
- `meta.last_refresh_at`: Current timestamp (ISO 8601)
- `meta.sources`: Array of source objects with `method`, `fetched_at`, `evidence` (collected during harvest)
- `meta.provenance_hash`: SHA-256 of canonical JSON fields (`id`+`handle`+`followers_count`+`verified`+`sources`)

**Rationale**:
- Enables end-to-end validation at every pipeline stage (harvest ‚Üí score ‚Üí export)
- Prevents "validate later" technical debt
- Proxy scoring unblocks M0 "scored" deliverable within API budget (‚â§150 calls)
- `provenance_hash` based on harvest-time fields is stable and reproducible
- **M0.0 Evidence**: 48 authors scored, range 0.0-82.3 (mean 37.7), 100% validation pass, manifest notes "v0_proxy_no_metrics"

**Alternative (Option B - REJECTED)**: Define separate intermediate schema and only validate final artifacts. Rejected because it creates schema drift risk and dual-contract maintenance burden.

---

## Evidence Requirements (M0)

Each author record MUST include:
```json
{
  "sources": [
    {
      "method": "github_seed" | "following_expansion" | "x_list",
      "fetched_at": "ISO 8601 timestamp",
      "evidence": "github.com/org/username" | "@seed_handle" | "x.com/i/lists/123"
    }
  ]
}
```

Provenance enables audit trail and reproducibility.

---

## Acceptance Criteria

### M1 Manual Scale Acceptance (Active)

**Reference**: T000004 M1 Manual Scale SUBPOR (to be created by PeerB)

**Goals**: 1.5k-2k authors over 4-5 weeks via manual CSV+Lists, ~250-300/week increments

**Guardrails**:
1. Entry filters enforced: `(verified + 30k) OR 50k followers`
2. Brand/risk exclusion mandatory: `confidence ‚â•0.7` (brand_heuristics.yml), auto-exclude categories (risk_terms.yml)
3. Schema validation 100% pass rate
4. Daily snapshots via `.github/workflows/snapshot.yml`
5. Provenance tracking (sources array with method/fetched_at/evidence per author)

**Weekly Batch Releases**:
- Weeks 1-4: ‚â•250 authors/week
- Week 5: ‚â•150 authors (buffer)
- Cumulative CI green status

**Final Deliverable**:
- `data/latest/latest.jsonl.gz` with manifest.count ‚àà [1500,2000]
- SHA-256 verified, score distribution reasonable (proxy v0: mean 40-60, range 0-100)
- Zero brand/official contamination in spot-check samples (N=30 per batch)

**QA Validation**: 50-record sample per 300-author batch, second-review signoff on edge cases

---

## ‚è∏Ô∏è DEFERRED: M0 Automation Acceptance Criteria (Reference Only)

### T000002 github-seeds Probe (Minimal Validation) - DEFERRED
**Scope**: Implement `influx-harvest github-seeds` with 4 orgs (openai, anthropic, pytorch, huggingface)

**Output**: `.cccc/work/foreman/probe-20251113/github_seeds.sample.jsonl`

**Acceptance**:
1. **File exists** with ‚â•5 author records (one JSONL object per line)
2. **Schema validation passes**: `python3 tools/influx-validate -s schema/bigv.schema.json github_seeds.sample.jsonl` exits with code 0
3. **Required fields present** in each record:
   - Core: `id`, `handle`, `name`, `verified`, `followers_count`, `lang_primary`, `topic_tags`
   - Meta placeholders: `meta.score=0`, `meta.last_refresh_at`, `meta.sources` (‚â•1 item with `method="github_seed"`, `fetched_at`, `evidence`), `meta.provenance_hash`
4. **Dedup/filter logic**: Code includes placeholder functions for deduplication (by `id` or `handle`) and brand/risk filtering (may be no-op for probe)
5. **One-shot command documented**: README at `.cccc/work/foreman/probe-20251113/README.md` includes exact command to reproduce, output path, and timestamp

**Evidence**: Commit with probe output file + README; validation passes in CI

### Following Slice-1 Probe (Minimal Graph Expansion Validation) - DEFERRED
**Scope**: Implement `influx-harvest following` with 5 seed authors (first 5 records from `github_seeds.sample.jsonl`) √ó 1 page per seed

**Status**: ‚è∏Ô∏è DEFERRED to M2 (requires Twitter v2 enrollment + GitHub seed layer)

**Input**: `.cccc/work/foreman/probe-20251113/github_seeds.sample.jsonl` (first 5 records only, prioritize those with X user IDs already resolved)

**Output**: `.cccc/work/foreman/probe-20251113/following.sample.jsonl`

**Acceptance**:
1. **Strict entry filters applied**: `(verified == true AND followers_count >= 30000) OR followers_count >= 50000`
2. **Brand/risk rules enforced**: Brand heuristics (`lists/rules/brand_heuristics.yml`) and risk terms (`lists/rules/risk_terms.yml`) applied; branded/risky accounts excluded
3. **Pagination locked**: Exactly 1 page per seed (`--pages=1`), no automatic expansion
4. **Output threshold**: ‚â•50 author records after filters
5. **Schema validation passes**: `python3 tools/influx-validate -s schema/bigv.schema.json following.sample.jsonl` exits with code 0
6. **Meta placeholders present**: Each record includes Option A meta fields (`score=0`, `last_refresh_at`, `sources` with `method="following_expansion"`, `provenance_hash`)
7. **API call tracking**: Execution logs record actual API call count (expected: 5-10 calls for 5 seeds √ó 1 page)
8. **Boundary enforcement**: If output count <50, log reason (insufficient follows passing filters, seed accounts suspended, etc.) and **STOP** - do NOT increase pages or seed count without explicit approval

**Command**:
```bash
influx-harvest following \
  --seeds .cccc/work/foreman/probe-20251113/github_seeds.sample.jsonl \
  --limit-seeds 5 \
  --pages 1 \
  --out .cccc/work/foreman/probe-20251113/following.sample.jsonl
```

**Evidence**: Commit with probe output file + command/results in T000002 SUBPOR REV section; validation passes

**Risk Mitigation**: Locks slice boundaries (5 seeds √ó 1 page) to prevent scope creep during probing; if ‚â•50 output demonstrates following-graph viability, proceed to full M0; if <50, diagnose bottleneck (filter too strict? seed quality?) before expanding

**Cross-reference**: POR.md:L25 execution guardrails (API‚â§150/run, TWITTER_FOLLOWING‚â§2 pages/seed, entry filters, brand/risk rules mandatory, Option A meta placeholders)

### Full M0 Pipeline (End-to-End) - DEFERRED
**Scope**: Complete collection pipeline producing 400-600 scored authors

**Status**: ‚è∏Ô∏è DEFERRED to M2 (automation path blocked per T000003)

**Acceptance**:
1. **Data flow completes**: GitHub seeds (160-200) ‚Üí following expansion (160-200) ‚Üí merge+dedupe (~320-400) ‚Üí [optional: x-lists +40-80] ‚Üí score ‚Üí export
2. **Final output**: `data/latest/latest.jsonl.gz` + `manifest.json`
   - Count: 400-600 authors
   - Sorting: score desc ‚Üí followers desc ‚Üí handle lex
   - Manifest: schema_version, timestamp, count, sha256 match file
3. **Schema validation**: All intermediate and final outputs pass `influx-validate`
4. **Rate limits respected**: Execution logs show ‚â§150 API calls per run; no 429 errors with retry-after >60s
5. **Provenance complete**: Each author has ‚â•1 source with method/fetched_at/evidence
6. **CI green**: All workflows pass (.github/workflows/validate.yml)

**Evidence**: Release tag YYYYMMDD with data/ artifact; POR Portfolio Health updated; xoperator ingests without error

### Rate Limit Feasibility Confirmation

**‚â§150 API calls per run** is feasible for M0:
- **GitHub org members** (4 orgs √ó ~10-15 members): ~50-60 calls (GITHUB_SEARCH_USERS + GITHUB_GET_A_USER per member to extract `twitter_username`)
- **Twitter user lookup** (~40-50 unique handles): ~1-2 calls (TWITTER_USER_LOOKUP_BY_USERNAMES batches 100 usernames per call)
- **Following expansion** (40-50 seeds √ó 2 pages): ~80-100 calls (TWITTER_FOLLOWING_BY_USER_ID)
- **Total**: ~131-162 calls (probe with 4 orgs is within budget; scale to 16 orgs requires batching into 3-4 runs)

**‚â§2 pages per seed** trade-off:
- **Pros**: Stays within free-tier rate limits; ~200 follows per seed is sufficient for high-signal diversity
- **Cons**: Misses long-tail follows (seeds with >200 follows get truncated)
- **Mitigation**: Prioritize high-centrality seeds (verified accounts with >100k followers likely follow other high-signal accounts in top 200)

**Acceptance**: M0 execution completes without rate limit blocks; adjust batch size if needed (split 16 orgs into smaller runs)

---

## M0.1 One-shot Run (Manual CSV Pipeline)

**Context**: M0.0 validated proxy scoring with 48 authors; M0.1 scales to 150-200 via manual CSV curation (Bet 1 automation paths blocked by GitHub OAuth + Twitter v2 enrollment).

### Prerequisites
- Curated seed CSV in `lists/seeds/m0_1_seeds.csv` (format: `handle,name,note,source_url`)
- 80-120 additional handles from X Lists + public team pages
- Tools: `influx-validate`, `influx-score`, `influx-export` (implemented with proxy scoring v0)

### Command Sequence

**Step 1: Prepare seed CSV** (manual curation, 2-3h):
```bash
# Create M0.1 seed CSV (combines T000002's 48 + new 80-120 handles)
# Format: handle,name,note,source_url
# Example:
# sama,Sam Altman,OpenAI CEO,https://github.com/openai
# karpathy,Andrej Karpathy,Tesla AI Director,https://github.com/tesla

# Save to lists/seeds/m0_1_seeds.csv
```

**Step 2: Fetch Twitter profiles** (using RUBE MCP TWITTER_USER_LOOKUP_BY_USERNAMES):
```bash
# Input: lists/seeds/m0_1_seeds.csv (handles column)
# Method: TWITTER_USER_LOOKUP_BY_USERNAMES (batches 100 handles/call)
# Output: raw_profiles.jsonl
# Expected: ~2-3 API calls for 150-200 handles
```

**Step 3: Filter & format** (apply entry filters + brand/risk rules):
```bash
# Apply filters:
# - Entry: (verified + 30k followers) OR 50k followers
# - Brand: lists/rules/brand_heuristics.yml (exclude Official/News/PR/etc)
# - Risk: lists/rules/risk_terms.yml (exclude nsfw/political/etc)
# Add meta placeholders: score=0 (pre-scoring), sources, last_refresh_at, provenance_hash
# Output: filtered.jsonl
```

**Step 4: Proxy scoring**:
```bash
python3 tools/influx-score update \
  --input filtered.jsonl \
  --out scored.jsonl

# Formula: 20*log10(followers/1000) + verified_boost [0,100]
# Output: scored.jsonl (all records with meta.score populated)
```

**Step 5: Validation**:
```bash
python3 tools/influx-validate \
  -s schema/bigv.schema.json \
  scored.jsonl

# Expected: 100% pass for ‚â•150 records
```

**Step 6: Export to latest**:
```bash
python3 tools/influx-export latest \
  --input scored.jsonl \
  --out data/latest/

# Output:
# - data/latest/latest.jsonl.gz (sorted: score desc ‚Üí followers desc ‚Üí handle lex)
# - data/latest/manifest.json (count, sha256, score_version=v0_proxy_no_metrics)
```

**Step 7: Final validation**:
```bash
python3 tools/influx-validate \
  -s schema/bigv.schema.json \
  data/latest/latest.jsonl.gz

# Confirm: ‚â•150 records, 100% pass
```

### M0.1 Acceptance Criteria
- ‚úì `data/latest/latest.jsonl.gz` count ‚â•150
- ‚úì Schema validation 100% pass
- ‚úì Manifest updated (count, sha256, score_version=v0_proxy_no_metrics)
- ‚úì Score distribution reasonable (e.g., min 0, max <100, mean 30-50)
- ‚úì Brand/risk filters applied (documented in manifest or SUBPOR)
- ‚úì Deterministic: Same seed CSV ‚Üí same output (stable sort + deterministic proxy scoring)

### M0.0 Baseline (Reference)
- **Commit**: 4060da8
- **Tag**: v0.0.0-m0.0
- **Count**: 48 authors
- **Score range**: 0.0-82.3 (mean 37.7)
- **Validation**: 48/48 pass
- **SHA-256**: 43b89903656fbf1d632291fd3de325699a76f2eb7499fd6cfd9eed66ae454345

---

## Appendix: M1 Execution Notes

### Cheapest Probe (M1 Batch 0.5)
**Purpose**: Empirical velocity validation before 4-5 week commitment
**Scope**: 50-100 authors from 1-2 domains (AI/Tech + Business), ‚â§2 days
**Deliverables**:
- `.cccc/work/m1/batch05/harvest.filtered.jsonl` (‚â•50 records)
- Validation 100% pass
- Velocity log showing sustained rate (‚â•15-20 records/hour)

**Acceptance**: Velocity measurement confirms 250-300/week assumption; if <150/week sustained rate detected, re-scope or add curator.

### Heuristics Shadow-Mode Validation
**Before**: M1 batch 1 begins
**Method**: Run brand/risk rules on labeled gold set (N=300-400, dual-reviewed)
**Metrics**: Precision/recall per flag category
**Acceptance**: Brand leakage ‚â§1%, high-severity risk false negatives ‚â§2%
**Output**: `.cccc/work/validation/heuristics_validation_report.json`

---

**Last Updated**: 2025-11-13 (v1.1.0 refactor)
**Refs**: POR#L38-39 (M1 strategy), T000003 (auth closure), commit 9779756 (filter spec), commit 6fd9487 (filter implementation), Aux strategic review 2025-11-13
