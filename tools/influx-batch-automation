#!/usr/bin/env python3
"""
influx-batch-automation: Complete workflow automation for M1 scaling

Automates the full pipeline: CSV ‚Üí Twitter lookup ‚Üí Harvest ‚Üí Score ‚Üí Integrate
with parallel processing, quality validation, and performance metrics.

Usage:
    influx-batch-automation run --seeds-dir lists/seeds/ --target-authors 1500
    influx-batch-automation validate --input data/latest/latest.jsonl
    influx-batch-automation report --output-dir archive/bulk_results/
"""
import argparse
import asyncio
import json
import sys
import os
import subprocess
import time
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


class BatchAutomation:
    """Complete workflow automation for M1 scaling"""
    
    def __init__(self, target_authors: int = 1500):
        self.target_authors = target_authors
        self.start_time = time.time()
        self.metrics = {
            'start_time': datetime.now(timezone.utc).isoformat(),
            'target_authors': target_authors,
            'current_authors': 0,
            'new_authors_added': 0,
            'batches_processed': 0,
            'total_processing_time': 0,
            'authors_per_hour': 0,
            'quality_compliance_rate': 0,
            'schema_validation_passed': 0,
            'schema_validation_failed': 0
        }
    
    def get_current_author_count(self) -> int:
        """Get current author count from latest dataset"""
        try:
            manifest_path = Path("data/latest/manifest.json")
            if manifest_path.exists():
                with open(manifest_path, 'r') as f:
                    manifest = json.load(f)
                    return manifest.get('count', 0)
        except Exception as e:
            logger.warning(f"Could not read current author count: {e}")
        return 0
    
    def run_command(self, cmd: List[str], description: str) -> Tuple[bool, str, str]:
        """Run a command and capture output"""
        logger.info(f"Running: {description}")
        logger.debug(f"Command: {' '.join(cmd)}")
        
        try:
            result = subprocess.run(
                cmd, 
                capture_output=True, 
                text=True, 
                timeout=1800  # 30 minute timeout
            )
            
            success = result.returncode == 0
            stdout = result.stdout
            stderr = result.stderr
            
            if success:
                logger.info(f"‚úÖ {description} completed successfully")
            else:
                logger.error(f"‚ùå {description} failed (exit code {result.returncode})")
                if stderr:
                    logger.error(f"Error: {stderr}")
                    
            return success, stdout, stderr
            
        except subprocess.TimeoutExpired:
            logger.error(f"‚è∞ {description} timed out after 30 minutes")
            return False, "", "Command timed out"
        except Exception as e:
            logger.error(f"üí• {description} crashed: {e}")
            return False, "", str(e)
    
    def run_bulk_harvest(self, seeds_dir: str, batch_size: int = 75) -> bool:
        """Run bulk harvesting with enhanced batch processing"""
        cmd = [
            sys.executable, "tools/influx-batch-harvest", "bulk",
            "--seeds-dir", seeds_dir,
            "--batch-size", str(batch_size),
            "--parallel-batches", "3",
            "--output-dir", "archive/bulk_results"
        ]
        
        success, stdout, stderr = self.run_command(
            cmd, "Bulk harvesting with RUBE MCP"
        )
        
        if success:
            # Parse results to find the latest output file
            # Look for bulk_results_*.jsonl in output directory
            output_dir = Path("archive/bulk_results")
            if output_dir.exists():
                result_files = list(output_dir.glob("bulk_results_*.jsonl"))
                if result_files:
                    latest_file = max(result_files, key=lambda p: p.stat().st_mtime)
                    logger.info(f"üìÑ Bulk harvest results: {latest_file}")
                    
                    # Count new authors
                    try:
                        author_count = 0
                        with open(latest_file, 'r') as f:
                            for line in f:
                                if line.strip():
                                    author_count += 1
                        self.metrics['new_authors_added'] = author_count
                        logger.info(f"üìä Harvested {author_count} new authors")
                    except Exception as e:
                        logger.error(f"Failed to count harvested authors: {e}")
        
        return success
    
    def run_scoring(self, input_file: str) -> bool:
        """Run scoring on harvested data"""
        output_file = input_file.replace('.jsonl', '_scored.jsonl')
        
        cmd = [
            sys.executable, "tools/influx-score", "update",
            "--input", input_file,
            "--out", output_file
        ]
        
        success, stdout, stderr = self.run_command(
            cmd, f"Scoring harvested data"
        )
        
        return success
    
    def integrate_with_main_dataset(self, scored_file: str) -> bool:
        """Integrate scored data with main dataset"""
        cmd = [
            sys.executable, "tools/influx-export", "latest",
            "--input", scored_file,
            "--out", "data/latest/"
        ]
        
        success, stdout, stderr = self.run_command(
            cmd, "Integrating with main dataset"
        )
        
        return success
    
    def run_validation(self, dataset_file: str = "data/latest/latest.jsonl") -> bool:
        """Run schema validation"""
        cmd = [
            sys.executable, "tools/influx-validate",
            "-s", "schema/bigv.schema.json",
            dataset_file
        ]
        
        success, stdout, stderr = self.run_command(
            cmd, "Schema validation"
        )
        
        # Update validation metrics
        if success:
            self.metrics['schema_validation_passed'] += 1
        else:
            self.metrics['schema_validation_failed'] += 1
            
        return success
    
    def calculate_quality_metrics(self) -> Dict:
        """Calculate quality and performance metrics"""
        current_time = time.time()
        processing_time = current_time - self.start_time
        
        self.metrics.update({
            'total_processing_time': processing_time,
            'authors_per_hour': (self.metrics['new_authors_added'] / processing_time) * 3600 if processing_time > 0 else 0,
            'current_authors': self.get_current_author_count()
        })
        
        # Calculate quality compliance rate
        total_validations = self.metrics['schema_validation_passed'] + self.metrics['schema_validation_failed']
        if total_validations > 0:
            self.metrics['quality_compliance_rate'] = (self.metrics['schema_validation_passed'] / total_validations) * 100
        
        return self.metrics
    
    def generate_report(self, output_dir: str = "archive/bulk_results") -> str:
        """Generate performance and quality report"""
        metrics = self.calculate_quality_metrics()
        
        report = f"""
# M1 Batch Processing Automation Report
Generated: {datetime.now(timezone.utc).isoformat()}

## Executive Summary
- **Target Authors**: {metrics['target_authors']}
- **Current Authors**: {metrics['current_authors']}
- **New Authors Added**: {metrics['new_authors_added']}
- **Progress to Target**: {(metrics['current_authors'] / metrics['target_authors']) * 100:.1f}%

## Performance Metrics
- **Processing Time**: {metrics['total_processing_time']:.1f} seconds
- **Authors per Hour**: {metrics['authors_per_hour']:.1f}
- **Batches Processed**: {metrics['batches_processed']}
- **Quality Compliance Rate**: {metrics['quality_compliance_rate']:.1f}%

## Validation Results
- **Schema Validation Passed**: {metrics['schema_validation_passed']}
- **Schema Validation Failed**: {metrics['schema_validation_failed']}

## Efficiency Improvements
- **Batch Size**: 50-100 authors per batch (vs 4-19 previously)
- **Parallel Processing**: 3 concurrent batches
- **Throughput**: {metrics['authors_per_hour']:.0f} authors/hour
- **Quality Maintained**: {metrics['quality_compliance_rate']:.1f}% schema compliance

## Recommendations
"""
        
        if metrics['current_authors'] < metrics['target_authors']:
            remaining = metrics['target_authors'] - metrics['current_authors']
            estimated_hours = remaining / metrics['authors_per_hour'] if metrics['authors_per_hour'] > 0 else float('inf')
            report += f"""
- **Continue Processing**: {remaining} more authors needed
- **Estimated Time**: {estimated_hours:.1f} hours at current throughput
- **Next Steps**: Process remaining seed files in lists/seeds/
"""
        else:
            report += """
- **Target Achieved**: M1 scaling goal completed
- **Next Phase**: Prepare for M2 production analytics
- **Quality Assurance**: Continue monitoring schema compliance
"""
        
        # Save report
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        report_file = output_path / f"automation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(report_file, 'w') as f:
            f.write(report)
        
        # Save metrics as JSON
        metrics_file = output_path / f"automation_metrics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(metrics_file, 'w') as f:
            json.dump(metrics, f, indent=2)
        
        logger.info(f"üìã Report saved to: {report_file}")
        logger.info(f"üìä Metrics saved to: {metrics_file}")
        
        return str(report_file)
    
    def run_complete_workflow(self, seeds_dir: str) -> bool:
        """Run the complete automated workflow"""
        logger.info(f"üöÄ Starting M1 batch automation workflow")
        logger.info(f"üìä Target: {self.target_authors} authors")
        logger.info(f"üìÅ Seeds directory: {seeds_dir}")
        
        # Step 1: Bulk harvesting
        if not self.run_bulk_harvest(seeds_dir):
            logger.error("‚ùå Bulk harvesting failed")
            return False
        
        # Step 2: Find latest results file
        output_dir = Path("archive/bulk_results")
        result_files = list(output_dir.glob("bulk_results_*.jsonl"))
        if not result_files:
            logger.error("‚ùå No harvest results found")
            return False
            
        latest_file = max(result_files, key=lambda p: p.stat().st_mtime)
        logger.info(f"üìÑ Using harvest results: {latest_file}")
        
        # Step 3: Scoring
        if not self.run_scoring(str(latest_file)):
            logger.error("‚ùå Scoring failed")
            return False
        
        scored_file = latest_file.with_name(latest_file.stem.replace('bulk_results', 'bulk_results_scored') + '.jsonl')
        if not scored_file.exists():
            logger.error("‚ùå Scored file not found")
            return False
        
        # Step 4: Integration
        if not self.integrate_with_main_dataset(str(scored_file)):
            logger.error("‚ùå Integration failed")
            return False
        
        # Step 5: Validation
        if not self.run_validation():
            logger.error("‚ùå Validation failed")
            return False
        
        # Step 6: Generate report
        report_file = self.generate_report()
        
        logger.info("‚úÖ Complete workflow finished successfully")
        logger.info(f"üìã Report: {report_file}")
        
        return True
    
    def validate_dataset(self, input_file: str) -> bool:
        """Validate dataset and generate quality report"""
        logger.info(f"üîç Validating dataset: {input_file}")
        
        # Run schema validation
        if not self.run_validation(input_file):
            logger.error("‚ùå Schema validation failed")
            return False
        
        # Count authors
        try:
            author_count = 0
            with open(input_file, 'r') as f:
                for line in f:
                    if line.strip():
                        author_count += 1
            logger.info(f"üìä Total authors: {author_count}")
        except Exception as e:
            logger.error(f"Failed to count authors: {e}")
            return False
        
        # Generate validation report
        self.metrics['current_authors'] = author_count
        report_file = self.generate_report()
        
        logger.info(f"‚úÖ Validation completed")
        logger.info(f"üìã Report: {report_file}")
        
        return True


def main():
    parser = argparse.ArgumentParser(
        description="influx-batch-automation: Complete workflow automation for M1 scaling"
    )
    subparsers = parser.add_subparsers(dest="command", required=True)
    
    # run subcommand
    run_parser = subparsers.add_parser("run", help="Run complete automated workflow")
    run_parser.add_argument(
        "--seeds-dir", required=True,
        help="Directory containing seed CSV files"
    )
    run_parser.add_argument(
        "--target-authors", type=int, default=1500,
        help="Target number of authors (default: 1500)"
    )
    
    # validate subcommand
    validate_parser = subparsers.add_parser("validate", help="Validate dataset")
    validate_parser.add_argument(
        "--input", default="data/latest/latest.jsonl",
        help="Dataset file to validate (default: data/latest/latest.jsonl)"
    )
    
    # report subcommand
    report_parser = subparsers.add_parser("report", help="Generate performance report")
    report_parser.add_argument(
        "--output-dir", default="archive/bulk_results",
        help="Output directory for report (default: archive/bulk_results)"
    )
    
    args = parser.parse_args()
    
    if args.command == "run":
        automation = BatchAutomation(target_authors=args.target_authors)
        success = automation.run_complete_workflow(args.seeds_dir)
        sys.exit(0 if success else 1)
        
    elif args.command == "validate":
        automation = BatchAutomation()
        success = automation.validate_dataset(args.input)
        sys.exit(0 if success else 1)
        
    elif args.command == "report":
        automation = BatchAutomation()
        report_file = automation.generate_report(args.output_dir)
        print(f"Report generated: {report_file}")


if __name__ == "__main__":
    main()