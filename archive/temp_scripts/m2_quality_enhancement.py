#!/usr/bin/env python3
"""
M2 Quality Enhancement Execution
Resolves critical scoring crisis for 117 high-value authors
Executes 5 batches of 25 authors each with enhanced M2 scoring
"""

import json
import subprocess
import time
from datetime import datetime, timezone


def load_quality_enhancement_plan():
    """Load the quality enhancement plan"""
    with open("quality_enhancement_plan.json", "r") as f:
        return json.load(f)


def process_quality_enhancement_batch(batch_num, authors):
    """Process a single quality enhancement batch using M2 pipeline"""
    print(f"\nüöÄ PROCESSING QUALITY ENHANCEMENT BATCH {batch_num}")
    print(f"Authors: {len(authors)}")
    print(f"Total followers: {sum(a['followers'] for a in authors):,}")

    # Create handles file
    handles_file = f"quality_enhancement_batch_{batch_num}_handles.txt"
    with open(handles_file, "w") as f:
        f.write("\n".join([author["handle"] for author in authors]))

    # Step 1: Enhanced metrics collection
    output_file = f"quality_enhancement_batch_{batch_num}_refreshed.jsonl"
    cmd1 = [
        "./tools/influx-harvest",
        "bulk",
        "--handles-file",
        handles_file,
        "--out",
        output_file,
        "--batch-size",
        str(len(authors)),
        "--brand-rules",
        "lists/rules/brand_heuristics.yml",
        "--risk-rules",
        "lists/rules/risk_terms.yml",
    ]

    print(f"  üì° Capturing enhanced activity metrics...")
    result = subprocess.run(cmd1, capture_output=True, text=True)
    if result.returncode != 0:
        print(f"  ‚ùå Error in batch {batch_num}: {result.stderr}")
        return None

    # Step 2: Apply M2 scoring
    scored_file = f"quality_enhancement_batch_{batch_num}_scored.jsonl"
    cmd2 = [
        "./tools/influx-score",
        "update",
        "--authors",
        output_file,
        "--out",
        scored_file,
        "--model",
        "m2",
    ]

    print(f"  üéØ Applying M2 scoring model...")
    result = subprocess.run(cmd2, capture_output=True, text=True)
    if result.returncode != 0:
        print(f"  ‚ùå Error in M2 scoring batch {batch_num}: {result.stderr}")
        return None

    # Step 3: Validation
    cmd3 = [
        "python3",
        "tools/influx-validate",
        "--strict",
        "-s",
        "schema/bigv.schema.json",
        scored_file,
    ]

    print(f"  ‚úÖ Validating M2 scores...")
    result = subprocess.run(cmd3, capture_output=True, text=True)
    if result.returncode != 0:
        print(f"  ‚ö†Ô∏è  Validation warnings batch {batch_num}")
        print(f"     {result.stdout}")

    # Load and enhance scored authors with improvement tracking
    enhanced_authors = []
    with open(scored_file, "r") as f:
        for line in f:
            if line.strip():
                author_data = json.loads(line)
                handle = author_data.get("handle", "")

                # Find original author info for improvement tracking
                original_author = next(
                    (a for a in authors if a["handle"] == handle), None
                )

                if original_author:
                    # Add quality enhancement metadata
                    author_data["meta"]["quality_enhancement"] = True
                    author_data["meta"]["previous_score"] = original_author.get(
                        "current_score", 0
                    )
                    author_data["meta"]["score_improvement"] = author_data["meta"][
                        "score"
                    ] - original_author.get("current_score", 0)
                    author_data["meta"]["score_model"] = "m2_enhanced_v1"
                    author_data["meta"]["data_source"] = "twitter_api_enhanced"

                    enhanced_authors.append(author_data)

    # Save enhanced results
    with open(scored_file, "w") as f:
        for author in enhanced_authors:
            f.write(json.dumps(author) + "\n")

    # Calculate batch statistics
    total_improvement = sum(
        author["meta"]["score_improvement"] for author in enhanced_authors
    )
    avg_improvement = (
        total_improvement / len(enhanced_authors) if enhanced_authors else 0
    )

    print(f"‚úÖ Batch {batch_num} COMPLETE:")
    print(f"  Authors processed: {len(enhanced_authors)}")
    print(f"  Total score improvement: {total_improvement:.1f} points")
    print(f"  Average improvement: {avg_improvement:.1f} points")
    print(f"  Results saved: {scored_file}")

    return enhanced_authors


def execute_quality_enhancement():
    """Execute complete quality enhancement plan"""
    print("üöÄ M2 QUALITY ENHANCEMENT EXECUTION")
    print("=" * 60)
    print("Resolving critical scoring crisis for high-value authors")

    # Load quality enhancement plan
    plan = load_quality_enhancement_plan()
    batches = plan["batches"]

    print(f"\nüìã EXECUTION PLAN:")
    print(f"  Total batches: {len(batches)}")
    print(f"  Total authors: {plan['quality_crisis']['high_value_low_score_authors']}")
    print(
        f"  Expected improvement: {plan['quality_crisis']['total_score_improvement_potential']:.0f} points"
    )

    # Process each batch
    all_processed_authors = []
    batch_results = []

    for batch in batches:
        batch_num = batch["batch_num"]
        authors = batch["authors"]

        # Process the batch
        processed_authors = process_quality_enhancement_batch(batch_num, authors)

        if processed_authors:
            all_processed_authors.extend(processed_authors)

            # Calculate batch results
            total_improvement = sum(
                author["meta"]["score_improvement"] for author in processed_authors
            )
            batch_results.append(
                {
                    "batch_num": batch_num,
                    "authors_processed": len(processed_authors),
                    "total_improvement": total_improvement,
                    "avg_improvement": total_improvement / len(processed_authors),
                }
            )

        # Brief pause between batches
        if batch_num < len(batches):
            print(f"‚è≥ Waiting 30 seconds before next batch...")
            time.sleep(30)

    # Integrate all results into main dataset
    if all_processed_authors:
        print(f"\nüîó INTEGRATING RESULTS INTO MAIN DATASET...")

        # Create combined results file
        combined_file = "data/latest/quality_enhancement_results.jsonl"
        with open(combined_file, "w") as outfile:
            for author in all_processed_authors:
                outfile.write(json.dumps(author) + "\n")

        # Use m2_integration.py to merge results
        cmd = [
            "python3",
            "m2_integration.py",
            "--source",
            combined_file,
            "--output",
            "data/latest/latest.jsonl",
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            print(f"‚úÖ DATASET UPDATED SUCCESSFULLY")
        else:
            print(f"‚ùå DATASET UPDATE FAILED: {result.stderr}")
            # Fallback: manual integration
            print(f"üîÑ Attempting manual integration...")
            # This would require implementing manual merge logic

    # Generate final report
    print(f"\nüìä QUALITY ENHANCEMENT EXECUTION REPORT")
    print("=" * 60)

    total_authors_processed = len(all_processed_authors)
    total_improvement = sum(
        author["meta"]["score_improvement"] for author in all_processed_authors
    )
    avg_improvement = (
        total_improvement / total_authors_processed
        if total_authors_processed > 0
        else 0
    )

    print(f"üéØ EXECUTION SUMMARY:")
    print(f"  Authors processed: {total_authors_processed}")
    print(f"  Total score improvement: {total_improvement:.1f} points")
    print(f"  Average improvement: {avg_improvement:.1f} points")

    print(f"\nüìà BATCH BREAKDOWN:")
    for result in batch_results:
        print(
            f"  Batch {result['batch_num']}: {result['authors_processed']} authors, +{result['total_improvement']:.1f} points"
        )

    # Show top improvements
    if all_processed_authors:
        print(f"\nüèÜ TOP 10 SCORE IMPROVEMENTS:")
        top_improvements = sorted(
            all_processed_authors,
            key=lambda x: x["meta"]["score_improvement"],
            reverse=True,
        )[:10]
        for i, author in enumerate(top_improvements, 1):
            improvement = author["meta"]["score_improvement"]
            old_score = author["meta"]["previous_score"]
            new_score = author["meta"]["score"]
            print(f"  {i:2d}. {author['name']} (@{author['handle']}):")
            print(f"      {old_score:.1f} ‚Üí {new_score:.1f} (+{improvement:.1f})")

    # Save execution report
    execution_report = {
        "execution_date": datetime.now(timezone.utc).isoformat(),
        "plan_reference": "quality_enhancement_plan.json",
        "execution_summary": {
            "total_authors_processed": total_authors_processed,
            "total_score_improvement": total_improvement,
            "average_improvement": avg_improvement,
            "success_rate": len(all_processed_authors)
            / plan["quality_crisis"]["high_value_low_score_authors"]
            * 100,
        },
        "batch_results": batch_results,
        "top_improvements": [
            {
                "name": author["name"],
                "handle": author["handle"],
                "previous_score": author["meta"]["previous_score"],
                "new_score": author["meta"]["score"],
                "improvement": author["meta"]["score_improvement"],
            }
            for author in sorted(
                all_processed_authors,
                key=lambda x: x["meta"]["score_improvement"],
                reverse=True,
            )[:10]
        ],
    }

    with open("quality_enhancement_execution_report.json", "w") as f:
        json.dump(execution_report, f, indent=2)

    print(f"\nüìÅ Execution report saved: quality_enhancement_execution_report.json")
    print(f"üéØ QUALITY ENHANCEMENT EXECUTION COMPLETE")

    return all_processed_authors


if __name__ == "__main__":
    execute_quality_enhancement()
